# Realtime 채팅/Q&A 부하 테스트 계획

## 목적

445명 입장 테스트 성공에 이어, **Realtime 채팅/Q&A + Presence/크론까지 포함한 전체 부하 테스트**를 "재현 가능한 시나리오"로 체계화한다.

## 전제 조건

- **시스템 아키텍처**: Next.js + Supabase Realtime Broadcast
- **채팅**: Broadcast 기반 실시간 메시지 (`webinar:${webinarId}:messages`)
- **Q&A**: Postgres Changes 구독 (`webinar-${webinarId}-questions`)
- **Presence**: HTTP/RPC ping (120초 주기 ± 10초 지터)
- **통계**: 크론 작업(1분 주기) + 버킷 집계

## 목표 KPI

| 지표 | 목표 | 허용 오차 |
|------|------|----------|
| **API 성공률** | 99.9%+ | 0.1% |
| **Realtime 구독 성공률** | 99%+ | 1% |
| **메시지 전송→수신 지연 (p95)** | < 2초 | 초기 목표 |
| **메시지 누락률** | < 0.1% | 초기 목표 |
| **HTTP 에러 (400/401/409/500)** | 0 | 허용 오차 정의 필요 |
| **재연결 루프 발생** | 0 | 즉시 중단 |

## 테스트 규모 (단계별)

| 단계 | 사용자 수 | 목적 | 예상 시간 |
|------|----------|------|----------|
| **S1** | 50명 | 기본 기능 검증 | 5분 |
| **S2** | 200명 | 중간 규모 안정성 | 10분 |
| **S3** | 500명 | 대규모 안정성 | 15분 |
| **S4** | 1,000명 | 최대 부하 검증 | 20분 |

**권장 진행 순서**: S1 → S2 → S3 → S4 (단계별 검증 후 확장)

---

## 시나리오 A: Realtime 연결/구독 내구성

### 목적
Supabase Realtime 채널 구독이 대량 동시 접속에서 안정적인지 확인

### 행동 시퀀스
1. N명의 브라우저 세션 생성 (Playwright 다중 페이지)
2. `/webinar/{id}/live` 진입
3. `webinar:${webinarId}:messages` 채널 subscribe 완료까지 대기
4. `webinar-${webinarId}-questions` 채널 subscribe 완료까지 대기
5. 구독 상태 유지 (최소 5분)

### 측정 지표
- **subscribe 성공률**: `(SUBSCRIBED 횟수) / (전체 시도 횟수) * 100`
- **subscribe까지 걸린 시간**: p50, p95, p99
- **CHANNEL_ERROR 이벤트 횟수**: 0 목표
- **CLOSED 이벤트 횟수**: 0 목표 (의도적 해제 제외)
- **TIMED_OUT 이벤트 횟수**: 0 목표
- **재연결 시도 횟수**: 0 목표

### DoD (Definition of Done)
- ✅ subscribe 성공률 99%+
- ✅ 재연결 루프 없음 (SUBSCRIBED → CLOSED → SUBSCRIBED 반복 0)
- ✅ CHANNEL_ERROR 0
- ✅ subscribe 시간 p95 < 5초

### 실패 기준
- subscribe 성공률 < 95%
- 재연결 루프 발생 (3회 이상 반복)
- CHANNEL_ERROR 다수 발생 (전체의 5% 이상)

---

## 시나리오 B: 채팅 브로드캐스트 fan-out 테스트

### 목적
"한 명이 보낸 메시지가 전체에 퍼지는" 상황에서 안정성/지연 측정

### 행동 시퀀스
1. N명 모두 채널 구독 상태 유지
2. 그중 10명이 **10초 동안 초당 1개씩** 메시지 전송 (= 총 100 msg)
3. 나머지 N-10명은 수신만 수행 (메시지 카운트)
4. 각 수신자가 받은 메시지 수 기록

### 측정 지표
- **전송 API 성공률**: `(200/201 응답) / (전체 전송 시도) * 100`
- **메시지 수신 누락률**: `(100 - 실제 수신된 메시지 수) / 100 * 100`
- **전송→수신 지연**: p50, p95, p99 (밀리초)
- **중복 수신 횟수**: 동일 mid를 2회 이상 받은 경우
- **Broadcast 이벤트 수신률**: `(수신 이벤트 수) / (전송 메시지 수) * 100`

### DoD
- ✅ 전송 API 성공률 99.9%+
- ✅ 누락률 < 0.1% (초기 목표)
- ✅ 지연 p95 < 2초 (초기 목표)
- ✅ 중복 수신 0 (mid 기반 중복 제거 정상 작동)

### 실패 기준
- 누락률 > 1%
- 지연 p95 > 5초
- 중복 수신 다수 발생 (전체의 1% 이상)

---

## 시나리오 C: Q&A 생성/모더레이션 브로드캐스트 테스트

### 목적
질문 등록/답변/고정/숨김 등 상태 변경이 실시간으로 잘 동기화되는지 확인

### 행동 시퀀스
1. 50명이 질문 등록 (짧은 텍스트, 예: "질문 {번호}")
2. 관리자 1명이 다음 작업 수행:
   - 10개 답변 (`PATCH /api/questions/{id}` status: 'answered')
   - 10개 고정 (`PATCH /api/questions/{id}` pinned: true)
   - 10개 숨김 (`PATCH /api/questions/{id}` status: 'hidden')
3. 모든 클라이언트가 상태 변경 이벤트 수신/반영 확인

### 측정 지표
- **질문 생성 API 성공률**: `(201 응답) / (전체 생성 시도) * 100`
- **관리자 PATCH 성공률**: `(200 응답) / (전체 PATCH 시도) * 100`
- **클라이언트 상태 변경 수신률**: `(수신한 UPDATE 이벤트) / (전송한 PATCH) * 100`
- **상태 변경 지연**: p50, p95 (밀리초)
- **상태 불일치**: 운영 콘솔과 라이브 페이지의 질문 상태 차이

### DoD
- ✅ 질문 생성 API 성공률 99.9%+
- ✅ 관리자 PATCH 성공률 99.9%+
- ✅ 클라이언트 상태 변경 수신률 99%+
- ✅ 상태 변경 지연 p95 < 3초
- ✅ 운영 콘솔/라이브 페이지 상태 불일치 0

### 실패 기준
- 상태 변경 수신률 < 95%
- 상태 불일치 발생 (운영 콘솔과 라이브 페이지 차이)
- 지연 p95 > 5초

---

## 시나리오 D: Presence/ping + 통계 크론 동시 테스트

### 목적
실시간 기능과 별개로, ping과 통계 집계가 동시에 돌 때 DB가 버티는지 확인

### 행동 시퀀스
1. N명이 라이브 상태 유지 (탭 visible)
2. ping 주기(120초 ± 10초 지터)가 실제로 호출되게 **5~10분 유지**
3. 크론(1분 주기)도 동일 시간 동안 정상 실행
4. 관리자가 stats/access API 호출 (30~60초 주기)

### 측정 지표
- **ping API 성공률**: `(204 응답) / (전체 ping 시도) * 100`
- **ping 호출 주기**: 실제 평균 간격 (목표: 120초 ± 10초)
- **webinar_live_presence 업데이트율**: 분당 업데이트 수
- **크론 성공률**: 크론 로그에서 실패 없음 확인
- **stats/access 응답 시간**: p50, p95 (밀리초)
- **DB 연결 수**: Supabase 대시보드에서 모니터링
- **DB CPU 사용률**: Supabase 대시보드에서 모니터링

### DoD
- ✅ ping API 성공률 99%+
- ✅ 크론 누락 없음 (1분 주기 정상 실행)
- ✅ stats/access 응답 시간 p95 < 1초
- ✅ DB 연결 수 안정 (폭증 없음)
- ✅ DB CPU 사용률 < 80% (장기간)

### 실패 기준
- DB 연결 수 폭증 (정상 대비 2배 이상)
- DB CPU 사용률 > 90% (지속)
- 크론 누락 발생
- stats/access 응답 시간 p95 > 3초

---

## 시나리오 E: 장애 상황(Realtime 흔들림) 폴백 테스트

### 목적
Realtime 연결이 불안정할 때 폴백 폴링이 서버를 죽이지 않는지 확인

### 행동 시퀀스
1. N명이 정상 구독 상태 유지
2. 일부 클라이언트(10%)에서 네트워크를 끊었다 붙였다 (오프라인/온라인 토글)
3. 일부 클라이언트(5%)에서 채널을 강제로 unsubscribe/subscribe 반복
4. 폴백 폴링이 과도하게 켜지는지 확인

### 측정 지표
- **폴백 폴링 활성화 횟수**: fallbackOn이 true가 된 클라이언트 수
- **폴백 폴링 API 호출 수**: `/api/webinars/{id}/messages` 호출 횟수
- **DB 쿼리 수**: Supabase 대시보드에서 모니터링
- **재연결 시도 횟수**: 채널 재구독 시도 횟수
- **폴백→Realtime 복구 시간**: 폴백 활성화 후 Realtime 재연결까지 시간

### DoD
- ✅ 폴백 폴링 활성화 < 전체의 10% (네트워크 끊김 시에만)
- ✅ 폴백 폴링 API 호출 수 < 정상 폴링의 2배
- ✅ DB 쿼리 수 폭증 없음 (정상 대비 1.5배 이하)
- ✅ 재연결 시도 < 3회 (클라이언트당)

### 실패 기준
- 폴백 폴링 활성화 > 전체의 30%
- 폴백 폴링 API 호출 수 > 정상 폴링의 5배
- DB 쿼리 수 폭증 (정상 대비 3배 이상)
- 재연결 루프 발생 (무한 재시도)

### P1 이슈 확정 조건
폭증이 발생하면 **"P1-서킷브레이커"** 최우선으로 확정:
- 폴백 폴링 API 호출 수 > 정상 폴링의 10배
- DB 쿼리 수 폭증 (정상 대비 5배 이상)

---

## 테스트 도구 조합

### 1) API 부하 테스트: k6 또는 Artillery
- **대상**: enter, messages/create, questions/create, questions PATCH 등 HTTP API
- **장점**: 빠르고 재현 쉬움
- **단점**: WebSocket fan-out/구독 안정성은 못 봄

### 2) Realtime(WebSocket) 부하 테스트: Playwright 다중 페이지
- **대상**: 실제 브라우저 세션을 띄워서 `supabase.channel(...).subscribe()`까지 수행
- **장점**: 메시지 전송 후 다른 페이지가 수신했는지까지 확인 가능, "진짜 장애"를 잡을 수 있음
- **단점**: 리소스 많이 사용, 느림

### 권장 조합
- **k6 + Playwright 2트랙**이 가장 실전적
- API 부하는 k6로 빠르게 검증
- Realtime 구독/브로드캐스트는 Playwright로 실제 검증

---

## 결정 포인트

### Rate Limit 정의 필요
- **메시지 API**: 사용자당 초당 몇 개 허용? (현재 미정의 시 기본값 제안 필요)
- **질문 API**: 사용자당 초당 몇 개 허용? (현재 미정의 시 기본값 제안 필요)

### 관리자 Stats 폴링 주기
- **권장**: 30~60초 (기본값 30초)
- **테스트 중**: 60초로 고정하여 부하 최소화

### 폴백 폴링 상한
- **현재**: 상한 없음 (문제 가능성)
- **권장**: 최대 5초 주기, 3회 실패 시 30초로 백오프
- **P1 이슈**: 상한이 없으면 서킷브레이커 티켓 생성

---

## 다음 단계

1. **S2(200명) 기준 1회 풀셋** 먼저 실행
   - A~D 시나리오를 10분짜리로 한 번 돌리기
   - 문제 없으면 S3(500명)으로 확장

2. **결과 리포트 작성**
   - 각 시나리오별 KPI 달성 여부
   - 실패한 경우 근거 로그
   - 다음 단계 권장사항
